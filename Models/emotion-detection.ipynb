{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom tensorflow.keras.applications import VGG16, InceptionResNetV2\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.optimizers import Adam","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = \"/kaggle/input/sad-happy-neutral/dataset/train\" \ntest_dir = \"/kaggle/input/sad-happy-neutral/dataset/test\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = 48 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(#rotation_range = 180,\n                                         width_shift_range = 0.1,\n                                         height_shift_range = 0.1,\n                                         horizontal_flip = True,\n                                         rescale = 1./255,\n                                         #zoom_range = 0.2,\n                                         validation_split = 0.2\n                                        )\nvalidation_datagen = ImageDataGenerator(rescale = 1./255,\n                                         validation_split = 0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading Data from Directories","metadata":{}},{"cell_type":"code","source":"\ntrain_generator = train_datagen.flow_from_directory(directory = train_dir,\n                                                    target_size = (img_size,img_size),\n                                                    batch_size = 64,\n                                                    color_mode = \"grayscale\",\n                                                    class_mode = \"categorical\",\n                                                    subset = \"training\"\n                                                   )\nvalidation_generator = validation_datagen.flow_from_directory( directory = test_dir,\n                                                              target_size = (img_size,img_size),\n                                                              batch_size = 64,\n                                                              color_mode = \"grayscale\",\n                                                              class_mode = \"categorical\",\n                                                              subset = \"validation\"\n                                                             )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # Standard CNN Model","metadata":{}},{"cell_type":"code","source":"model= tf.keras.models.Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48, 48,1)))\nmodel.add(Conv2D(64,(3,3), padding='same', activation='relu' ))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128,(5,5), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n    \nmodel.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten()) \nmodel.add(Dense(256,activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n    \nmodel.add(Dense(512,activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.compile(\n    optimizer = Adam(lr=0.0001), \n    loss='categorical_crossentropy', \n    metrics=['accuracy']\n  )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 64\nbatch_size = 64","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x = train_generator,epochs = epochs,validation_data = validation_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model_optimal3.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = image.load_img(\"Random Image Url\",target_size = (48,48),color_mode = \"grayscale\")\nimg = np.array(img)\nplt.imshow(img)\nprint(img.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_dict = {0:'Happy',1:'Neutral',2:'Sad'}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = np.expand_dims(img,axis = 0) #makes image shape (1,48,48)\nimg = img.reshape(1,48,48,1)\nresult = model.predict(img)\nresult = list(result[0])\nprint(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_index = result.index(max(result))\nprint(label_dict[img_index])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss, train_acc = model.evaluate(train_generator)\ntest_loss, test_acc   = model.evaluate(validation_generator)\nprint(\"Train Accuracy =\" , train_acc , \"Validation Accuracy =\" , test_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(validation_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(validation_generator , predictions )\nimport seaborn as sns\nsns.heatmap(cm , annot = True , cmap='viridis')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model_optimal3.h5')","metadata":{},"execution_count":null,"outputs":[]}]}